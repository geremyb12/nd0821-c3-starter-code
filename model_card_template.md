# Model Card

## Model Details
The creator of this model is Geremy Bantug, created for a Nanodegree project. It is a logistic regression model that was trained to predict if salary is greater or less than $50k, using census data.
## Intended Use
The intended use of this model is for binary classification tasks where the input features consist of both numerical and categorical features of census bureau data. The output is a prediction if salary is greater or less than $50k.
## Training Data

The dataset utilized in this study originates from the UCI Machine Learning Repository's census dataset, accessible at https://archive.ics.uci.edu/ml/datasets/census+income.

Prior to analysis, the column names were stripped to eliminate any leading or trailing whitespaces. Also, hyphens were changed to underscores due to Pydantic's incompatible variable names.The dataset comprises 32,561 rows of data, including one header row.

For model training and evaluation purposes, the dataset was divided into a training set and a test set using an 80-20 split ratio. Stratification was applied based on the target feature 'salary' to ensure representative distribution across both sets.

To facilitate the utilization of the data during training and testing phases, categorical features underwent encoding using a OneHotEncoder with the parameters parse=False and handle_unknown="ignore". The labels were encoded using a LabelBinarizer with no additional parameters.
## Evaluation Data
The evaluation dataset is a random 20% of the training data generated by train_test_split of scikit-learn.
## Metrics
Performance on slices of just categorical features: \
"{'workclass': {'precision': 0.7115923793146262, 'recall': 0.41342512294205325, 'f1-score': 0.46148903338214536}, \
'education': {'precision': 0.9732418524871355, 'recall': 0.8112635791881075, 'f1-score': 0.7878673527730131}, \
'marital_status': {'precision': 0.5693946594693261, 'recall': 0.2744759996027369, 'f1-score': 0.4135535394201455}, \
'occupation': {'precision': 0.682857081701235, 'recall': 0.965260729757206, 'f1-score': 0.6628917712238125}, \
'relationship': {'precision': 0.46789802289282, 'recall': 0.933518416717672, 'f1-score': 0.42922084083334905}, \
'race': {'precision': 0.8040403912747367, 'recall': 0.49012399743638974, 'f1-score': 0.5172877442095926}, \
'sex': {'precision': 0.6695093457943926, 'recall': 0.27594511894186163, 'f1-score': 0.3886226954549936}, \
'native_country': {'precision': 0.7166458203043569, 'recall': 0.21051454138702458, 'f1-score': 0.3227621931125391}}"
## Ethical Considerations
The dataset contains various features such as gender, country of origin, and race, which are used to train the model. However, including these features in decision-making processes aimed at promoting equal opportunity can introduce biases and potentially result in unfair outcomes. Hence, it's crucial to exclude these features from the model to mitigate bias and uphold fairness in decision-making.
## Caveats and Recommendations
Training sample is fairly small and some features are unbalanced.